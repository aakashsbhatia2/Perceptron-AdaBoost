# Perceptron-AdaBoost
Implementation of Perceptron and AdaBoost using Python from scratch


I: Perceptron
Implement the perceptron learning algorithm. Using this code, I performed:
(i) empirical risk minimization
(ii) 10-fold cross-validation

For both tasks, you must the output provided is :
(i) the output hypothesis (i.e., the weight vector w), and
(ii) the error of prediction.

Adaptive Boosting 
Implement AdaBoost. For this task, Breast Cancer Prediction dataset dataset is used. For weak learners, hypothesis class of decision stumps on the five feature axes is implemented. Each weak hypothesis is of the form “if this
feature value is less than a, then y = 0, else y = 1”. Using this code, I performed:
(i) empirical risk minimization
(ii) 10-fold cross-validation

For both tasks, you must the output provided is :
(i) the output hypothesis (i.e., the weight vector w), and
(ii) the error of prediction.
